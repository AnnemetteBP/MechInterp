{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple, List, Dict, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\"\"\"import torch.nn as nn\n",
    "import torch.nn.functional as F\"\"\"\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tqdm\n",
    "\n",
    "from helper_utils.enum_keys import (\n",
    "    FPKey,\n",
    "    DirPath,\n",
    "    QuantStyle,\n",
    "    MiscPrompts,\n",
    "    Contexts,\n",
    "    Texts,\n",
    "    ModelKey\n",
    ")\n",
    "\n",
    "from PTQ.apply_ptq import applyPTQ\n",
    "\n",
    "import helper_utils.utils as utils\n",
    "\n",
    "from mech_interp_utils.utils_main.src.transformer_utils import (\n",
    "    logit_lens,\n",
    "    activation_lens,\n",
    "    dictionary_learning,\n",
    "    chatbot_analysis\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_DIR = 'Outputs/Report/LogitLens'\n",
    "SAE_DIR = 'Outputs/SAE'\n",
    "MISC_DIR = 'Outputs/Report/Misc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS:Dict = {\n",
    "    'context': Contexts.C1.value,\n",
    "    'prompt': MiscPrompts.Q2.value,\n",
    "    'max_new_tokens': 250,\n",
    "    'temperature': 0.8,\n",
    "    'repetition_penalty': 1.1,\n",
    "    'sample': True,\n",
    "    'device': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QuantStyle.BITNET.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load fp models func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_model(model_path:str, dtype=torch.dtype) -> AutoModelForCausalLM:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        return_dict=True,\n",
    "        output_hidden_states=True,\n",
    "        torch_dtype=dtype,\n",
    "        low_cpu_mem_usage=True,\n",
    "        local_files_only=True,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPKey.OLMO7B_FP.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPKey.OLMO1B_FP.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo1b_tokenizer = AutoTokenizer.from_pretrained(FPKey.OLMO1B_TOkENIZER.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo1b_fp16 = load_test_model(FPKey.OLMO1B_FP.value, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo1b_fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo1b_bitnet_fp32 = applyPTQ(\n",
    "    load_test_model(FPKey.OLMO7B_FP.value, dtype=torch.float32),\n",
    "    tokenizer=olmo1b_tokenizer,\n",
    "    calibration_input=MiscPrompts.Q11.value,\n",
    "    mode='1.58bit',\n",
    "    qkv_safety=False,\n",
    "    safer_quant=False,\n",
    "    ffq=False,\n",
    "    model_half=False,\n",
    "    quant_half=True,\n",
    "    layers_to_quant=QuantStyle.BITNET.value,\n",
    "    act_quant=True,\n",
    "    act_bits=8,\n",
    "    dropout_prob=0.0,\n",
    "    redundancy=0,\n",
    "    frame_dropout_prob=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NousResearch/DeepHermes-3-Llama-3-8B-Preview (NOT RUN YET!!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NousResearch/DeepHermes-3-Llama-3-3B-Preview (28 layers 0-27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep3b_tokenizer = AutoTokenizer.from_pretrained(FPKey.TOKENIZER_3B.value, local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep3b_fp32 = load_test_model(FPKey.FP16_3B.value, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep3b_fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep3b_fp16 = load_test_model(FPKey.FP16_3B.value, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in deep3b_fp32.named_parameters():\n",
    "    print(v.data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantized Deep Hermes 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep3b_fp32_158bit_ptsq = applyPTQ(\n",
    "    load_test_model(FPKey.FP16_3B.value, dtype=torch.float32),\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    calibration_input=\"The quick brown fox jumps over the  lazy dog\",\n",
    "    mode='1.58bit',\n",
    "    qkv_safety=False,\n",
    "    safer_quant=False,\n",
    "    ffq=False,\n",
    "    model_half=False,\n",
    "    quant_half=True,\n",
    "    layers_to_quant=QuantStyle.BITNET.value,\n",
    "    act_quant=True,\n",
    "    act_bits=8,\n",
    "    dropout_prob=0.0,\n",
    "    redundancy=0,\n",
    "    frame_dropout_prob=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep3b_fp32_158bit_ptsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.print_model_weights(deep3b_fp32_158bit_ptsq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=utils.get_weights(deep3b_fp32_158bit_ptsq)\n",
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep3b_fp32_2bit_ptsq_sym = applyPTQ(\n",
    "    load_test_model(FPKey.FP16_3B.value, dtype=torch.float32),\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    calibration_input=PARAMS.get('prompt'),\n",
    "    mode='8bit_sym',\n",
    "    qkv_safety=False,\n",
    "    safer_quant=False,\n",
    "    ffq=False,\n",
    "    model_half=False,\n",
    "    quant_half=False,\n",
    "    layers_to_quant=QuantStyle.BITNET.value,\n",
    "    act_quant=False,\n",
    "    act_bits=8,\n",
    "    dropout_prob=0.0,\n",
    "    redundancy=0,\n",
    "    frame_dropout_prob=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3B Version Dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"dict_3b_fp16_sym = {\n",
    "    #'3b-fp16': deep3b_fp16,\n",
    "    #'3b-fp16-1.58bit-ptsq': deep3b_fp16_158bit_ptsq,\n",
    "    #'3b-fp16-2bit-ptsq-sym': deep3b_fp16_2bit_ptsq_sym,\n",
    "    #'3b-fp16-2bit-ffsq-sym': deep3b_fp16_2bit_ffsq_sym,\n",
    "}\"\"\"\n",
    "\n",
    "dict_3b_fp32_sym = {\n",
    "    #'3b-fp32': deep3b_fp32,\n",
    "    '3b-fp32-1.58bit-ptsq': deep3b_fp32_158bit_ptsq,\n",
    "    #'3b-fp32-2bit-ffsq-sym': deep3b_fp32_2bit_ffsq_sym,\n",
    "    #'3b-fp32-2bit-ptsq-sym': deep3b_fp32_2bit_ptsq_sym\n",
    "}\n",
    "\"\"\"\n",
    "dict_3b_fp16_asym = {\n",
    "    '3b-fp16': deep3b_fp16,\n",
    "    '3b-fp16-1.58bit-ptsq': deep3b_fp16_158bit_ptsq,\n",
    "    '3b-fp16-2bit-ffsq-asym': deep3b_fp16_2bit_ffsq_asym,\n",
    "    '3b-fp16-2bit-ptsq-asym': deep3b_fp16_2bit_ptsq_asym\n",
    "}\n",
    "\n",
    "dict_3b_fp32_asym = {\n",
    "    '3b-fp32': deep3b_fp32,\n",
    "    '3b-fp32-1.58bit-ptsq': deep3b_fp32_158bit_ptsq,\n",
    "    '3b-fp32-2bit-ffsq-asym': deep3b_fp32_2bit_ffsq_asym,\n",
    "    '3b-fp32-2bit-ptsq-asym': deep3b_fp32_2bit_ptsq_asym\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_analysis.run_chatbot_analysis(\n",
    "    models=dict_3b_fp32_sym,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    #device='cpu',\n",
    "    full_path='logs/chatbot_logs/DeepHermes3B/SymPTQ'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_analysis.plot_chatbot_analysis(\n",
    "    json_logs='logs/chatbot_logs/DeepHermes3B/SymPTQ',\n",
    "    parallel_plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Lens and Logit Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_logit_lens(\n",
    "    model=olmo1b_fp16,\n",
    "    tokenizer=olmo1b_tokenizer,\n",
    "    input_ids=MiscPrompts.Q11.value,\n",
    "    start_ix=0, end_ix=15,\n",
    "    save_fig_path=None,\n",
    "    #save_fig_path='Outputs/FP/ll_nwd_deep3b_fp16_math.png',\n",
    "    #entropy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep3b_fp32_158bit_ptsq.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_logit_lens(\n",
    "    model=olmo1b_bitnet_fp32,\n",
    "    tokenizer=olmo1b_tokenizer,\n",
    "    input_ids=MiscPrompts.Q11.value,\n",
    "    start_ix=0, end_ix=15,\n",
    "    save_fig_path=None,\n",
    "    #save_fig_path='Outputs/FP/ll_logits_deep3b_fp32_math.png',\n",
    "    #probs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_logit_lens(\n",
    "    model=deep3b_fp32_158bit_ptsq,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    save_fig_path=None,\n",
    "    #save_fig_path='Outputs/PTQ/ll_logits_deep3b_fp32_158bit_sym-math.png',\n",
    "    #probs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_comparing_lens(\n",
    "    models=(deep3b_fp32, deep3b_fp32_158bit_ptsq),\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    save_fig_path='Outputs/PTQ/ll_nwd_deep3b_fp32_158bit_sym-math.png',\n",
    "    #save_fig_path=None,\n",
    "    wasserstein=True,\n",
    "    #top_down=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_comparing_lens(\n",
    "    models=(deep3b_fp32, deep3b_2bit_ffsq_sym),\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    #save_fig_path=f\"{DirPath.LENS_VIS.value}/compare_nwd_deep3bfpptsq158bit_math.jpg\",\n",
    "    save_fig_path=None,\n",
    "    wasserstein=True,\n",
    "    #top_down=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_topk_lens(\n",
    "    model=deep3b_fp32,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    topk_n=5,\n",
    "    #save_fig_path=f\"{DirPath.LENS_VIS.value}/topk_5_logits_deep3bfp32_math.jpg\",\n",
    "    save_fig_path=None,\n",
    "    #entropy=True,\n",
    "    #top_down=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_topk_lens(\n",
    "    model=deep3b_2bit_ffsq_sym,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    topk_n=5,\n",
    "    #save_fig_path=f\"{DirPath.LENS_VIS.value}/topk_5_logits_deep3bfp32_math.jpg\",\n",
    "    save_fig_path=None,\n",
    "    #entropy=True,\n",
    "    #top_down=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_topk_lens(\n",
    "    model=deep3b_2bit_ptsq_sym,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    topk_n=5,\n",
    "    #save_fig_path=f\"{DirPath.LENS_VIS.value}/topk_5_logits_deep3bfp32_math.jpg\",\n",
    "    save_fig_path=None,\n",
    "    #entropy=True,\n",
    "    #top_down=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_lens.plot_activation_lens(\n",
    "    model=deep3b_fp32,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    metric='norm',\n",
    "    save_fig_path='Outputs/FP/act_norm_deep3b_fp32_math.png',\n",
    "    #save_fig_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_lens.plot_activation_lens(\n",
    "    model=deep3b_fp32_2bit_ptsq_sym,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    metric='norm',\n",
    "    #save_fig_path='Outputs/PTQ/act_norm_deep3b_fp32_158bi-math.png',\n",
    "    save_fig_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_lens.plot_activation_lens(\n",
    "    model=deep3b_fp32_158bit_ptsq,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    metric='norm',\n",
    "    #save_fig_path=f\"{DirPath.LENS_VIS.value}/act_norm_deep3b_fp32_math.jpg\",\n",
    "    save_fig_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_lens.plot_comparing_act_lens(\n",
    "    models=(deep3b_fp32, deep3b_fp32_158bit_ptsq),\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    metric='norm',\n",
    "    metric_name='l2',\n",
    "    save_fig_path='Outputs/PTQ/act_norm-l2_deep3b_fp32_158bit_sym-math.png',\n",
    "    #save_fig_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_lens.plot_comparing_act_lens(\n",
    "    models=(deep3b_fp32, deep3b_158bit_ptsq),\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    input_ids=PARAMS.get('prompt'),\n",
    "    start_ix=0, end_ix=16,\n",
    "    metric='norm',\n",
    "    metric_name='l2',\n",
    "    #save_fig_path=f\"{DirPath.LENS_VIS.value}/act_norml2_deep3b_fp_ffsq2bit_math.jpg\",\n",
    "    save_fig_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Learning: SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_tokens(\n",
    "    model=deep3b_fp32_158bit_ptsq,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    inputs=PARAMS.get('prompt'),\n",
    "    multi_tokens=False,\n",
    "    do_log=False,\n",
    "    target_layers=[5],\n",
    "    vis_projection=None,\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    fig_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_tokens(\n",
    "    model=deep3b_fp32_158bit_ptsq,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    inputs=PARAMS.get('prompt'),\n",
    "    multi_tokens=True,\n",
    "    do_log=False,\n",
    "    target_layers=[5],\n",
    "    vis_projection=None,\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    fig_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_heatmap(\n",
    "    model=deep3b_fp16_2bit_ptsq_sym,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    inputs=Texts.T1.value,\n",
    "    do_log=False,\n",
    "    top_k=5,\n",
    "    tokens_per_row=30,\n",
    "    target_layers=[5],\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    fig_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_heatmap(\n",
    "    model=deep3b_fp32,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    inputs=Texts.T1.value,\n",
    "    do_log=False,\n",
    "    top_k=5,\n",
    "    tokens_per_row=30,\n",
    "    target_layers=[5],\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    fig_path='Outputs/FP/sae5_deep3b_fp32_math.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_heatmap(\n",
    "    model=deep3b_fp32_158bit_ptsq,\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    inputs=Texts.T1.value,\n",
    "    do_log=False,\n",
    "    top_k=5,\n",
    "    tokens_per_row=30,\n",
    "    target_layers=[5],\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    #fig_path='Outputs/PTQ/sae5_deep3b_fp32_158bit_sym-math.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_comparing_heatmap(\n",
    "    models=(deep3b_fp32, deep3b_fp32_158bit_ptsq),\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    inputs=Texts.T1.value,\n",
    "    top_k=5,\n",
    "    tokens_per_row=30,\n",
    "    target_layers=[5],\n",
    "    fig_path='Outputs/PTQ/sae5_deep3b_fp32_158bit_sym-math.png',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_comparing_heatmap(\n",
    "    models=(deep3b_fp32, deep3b_158bit_ptsq),\n",
    "    tokenizer=deep3b_tokenizer,\n",
    "    inputs=Texts.T1.value,\n",
    "    top_k=5,\n",
    "    tokens_per_row=30,\n",
    "    target_layers=[5],\n",
    "    fig_path=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MechInterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
