{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Tuple, List, Dict, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, DownloadMode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tqdm\n",
    "\n",
    "from helper_utils.enum_keys import (\n",
    "    FPKey,\n",
    "    QuantStyle,\n",
    "    MiscPrompts,\n",
    "    Contexts,\n",
    "    Texts,\n",
    ")\n",
    "\n",
    "from PTQ.apply_ptq import applyPTQ\n",
    "from PTQ.olmo_act_fns import patch_olmo_mlp\n",
    "import helper_utils.utils as utils\n",
    "\n",
    "from mech_interp_utils.utils_main.src.transformer_utils import (\n",
    "    logit_lens,\n",
    "    activation_lens,\n",
    "    dictionary_learning,\n",
    "    chatbot_analysis\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset for calibrating activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r'D:\\ThesisData\\wikitext'\n",
    "\n",
    "destination_path = str(Path(filepath))\n",
    "dataset = load_dataset(\n",
    "    'wikitext', 'wikitext-103-raw-v1',\n",
    "    split={\n",
    "        'train': 'train[:30%]',\n",
    "        'validation': 'validation[:10%]',\n",
    "        'test': 'test[:10%]',\n",
    "    },\n",
    "    cache_dir=destination_path,\n",
    "    download_mode=DownloadMode.REUSE_DATASET_IF_EXISTS,\n",
    "    keep_in_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_texts = [t for t in dataset['train'][\"text\"] if isinstance(t, str) and t.strip()]\n",
    "#calibration_texts = [t for t in sub_txts[\"text\"] if isinstance(t, str) and t.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_txts = train_texts.take(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS:Dict = {\n",
    "    'context': Contexts.C1.value,\n",
    "    'prompt': MiscPrompts.Q11.value,\n",
    "    'max_new_tokens': 250,\n",
    "    'temperature': 0.8,\n",
    "    'repetition_penalty': 1.1,\n",
    "    'sample': True,\n",
    "    'device': None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_model(model_path:str, dtype=torch.dtype) -> AutoModelForCausalLM:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        return_dict=True,\n",
    "        output_hidden_states=True,\n",
    "        torch_dtype=dtype,\n",
    "        low_cpu_mem_usage=True,\n",
    "        local_files_only=True,\n",
    "        use_safetensors=True\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### allenai/OLMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo1b_tokenizer = AutoTokenizer.from_pretrained(FPKey.OLMO1B_TOKENIZER.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo2t_tokenizer = AutoTokenizer.from_pretrained(FPKey.OLMO7B2T_TOKENIZER.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo7b_tokenizer = AutoTokenizer.from_pretrained(FPKey.OLMO7B_TOKENIZER.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo1b_fp32 = load_test_model(FPKey.OLMO1B_FP.value, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo2t_fp32 = load_test_model(FPKey.OLMO7B2T_FP.value, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo7b_fp32 = load_test_model(FPKey.OLMO7B_FP.value, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo1b_fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo1b_fp32.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo1b_bitnet_fp32 = applyPTQ(\n",
    "    load_test_model(FPKey.OLMO1B_FP.value, dtype=torch.float32),\n",
    "    tokenizer=olmo1b_tokenizer,\n",
    "    calibration_input=None,\n",
    "    #calibration_input=sub_txts['text'],\n",
    "    #calibration_input=PARAMS.get('prompt'),\n",
    "    mode='1.58bit',\n",
    "    safer_quant=True,\n",
    "    model_half=False,\n",
    "    quant_half=False,\n",
    "    layers_to_quant_weights=QuantStyle.BITNET.value,\n",
    "    layers_to_quant_activations=QuantStyle.BITNET.value,\n",
    "    fragile_layers=False,\n",
    "    act_quant=False,\n",
    "    act_bits=8,\n",
    "    debugging=True,\n",
    "    plot_debugging=False,\n",
    "    plot_quantization=False,\n",
    "    freeze_modules=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo2t_bitnet_fp32 = applyPTQ(\n",
    "    load_test_model(FPKey.OLMO7B2T_FP.value, dtype=torch.float32),\n",
    "    tokenizer=olmo2t_tokenizer,\n",
    "    calibration_input=None,\n",
    "    #calibration_input=sub_txts['text'],\n",
    "    #calibration_input=PARAMS.get('prompt'),\n",
    "    mode='1.58bit',\n",
    "    safer_quant=True,\n",
    "    model_half=False,\n",
    "    quant_half=False,\n",
    "    layers_to_quant_weights=QuantStyle.BITNET.value,\n",
    "    layers_to_quant_activations=QuantStyle.BITNET.value,\n",
    "    fragile_layers=False,\n",
    "    act_quant=False,\n",
    "    act_bits=8,\n",
    "    debugging=True,\n",
    "    plot_debugging=False,\n",
    "    plot_quantization=False,\n",
    "    freeze_modules=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo2t_bitnet_fp32 = applyPTQ(\n",
    "    load_test_model(FPKey.OLMO7B_FP.value, dtype=torch.float32),\n",
    "    tokenizer=olmo7b_tokenizer,\n",
    "    calibration_input=None,\n",
    "    #calibration_input=sub_txts['text'],\n",
    "    #calibration_input=PARAMS.get('prompt'),\n",
    "    mode='1.58bit',\n",
    "    safer_quant=True,\n",
    "    model_half=False,\n",
    "    quant_half=False,\n",
    "    layers_to_quant_weights=QuantStyle.BITNET.value,\n",
    "    layers_to_quant_activations=QuantStyle.BITNET.value,\n",
    "    fragile_layers=False,\n",
    "    act_quant=False,\n",
    "    act_bits=8,\n",
    "    debugging=True,\n",
    "    plot_debugging=False,\n",
    "    plot_quantization=False,\n",
    "    freeze_modules=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olmo2t_bitnet_fp32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NousResearch/DeepHermes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh3b_tokenizer = AutoTokenizer.from_pretrained(FPKey.TOKENIZER_3B.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh8b_tokenizer = AutoTokenizer.from_pretrained(FPKey.TOKENIZER_8B.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh3b_fp32 = load_test_model(FPKey.FP_3B.value, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh8b_fp32 = load_test_model(FPKey.FP_8B.value, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh3b_bitnet_fp32 = applyPTQ(\n",
    "    load_test_model(FPKey.FP_3B.value, dtype=torch.float32),\n",
    "    tokenizer=dh3b_tokenizer,\n",
    "    calibration_input=None,\n",
    "    #calibration_input=sub_txts['text'],\n",
    "    #calibration_input=PARAMS.get('prompt'),\n",
    "    mode='1.58bit',\n",
    "    safer_quant=True,\n",
    "    model_half=False,\n",
    "    quant_half=False,\n",
    "    layers_to_quant_weights=QuantStyle.BITNET.value,\n",
    "    layers_to_quant_activations=QuantStyle.BITNET.value,\n",
    "    fragile_layers=False,\n",
    "    act_quant=False,\n",
    "    act_bits=8,\n",
    "    debugging=True,\n",
    "    plot_debugging=False,\n",
    "    plot_quantization=False,\n",
    "    freeze_modules=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh3b_bitnet_fp32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh8b_bitnet_fp32 = applyPTQ(\n",
    "    load_test_model(FPKey.FP_8B.value, dtype=torch.float32),\n",
    "    tokenizer=dh8b_tokenizer,\n",
    "    calibration_input=None,\n",
    "    #calibration_input=sub_txts['text'],\n",
    "    #calibration_input=PARAMS.get('prompt'),\n",
    "    mode='1.58bit',\n",
    "    safer_quant=True,\n",
    "    model_half=False,\n",
    "    quant_half=False,\n",
    "    layers_to_quant_weights=QuantStyle.BITNET.value,\n",
    "    layers_to_quant_activations=QuantStyle.BITNET.value,\n",
    "    fragile_layers=False,\n",
    "    act_quant=False,\n",
    "    act_bits=8,\n",
    "    debugging=True,\n",
    "    plot_debugging=False,\n",
    "    plot_quantization=False,\n",
    "    freeze_modules=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh8b_bitnet_fp32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Lens and Logit Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MiscPrompts.Q2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh8b_fp32.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_logit_lens(\n",
    "    model=dh3b_fp32,\n",
    "    tokenizer=dh3b_tokenizer,\n",
    "    input_ids=MiscPrompts.Q2.value,\n",
    "    start_ix=0, end_ix=15,\n",
    "    #save_fig_path=None,\n",
    "    save_fig_path='Outputs/LogitLens/DH3B/logits_3b_fp32_math.jpg',\n",
    "    #entropy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_logit_lens(\n",
    "    model=dh3b_bitnet_fp32,\n",
    "    tokenizer=dh3b_tokenizer,\n",
    "    input_ids=MiscPrompts.Q2.value,\n",
    "    start_ix=0, end_ix=15,\n",
    "    #save_fig_path=None,\n",
    "    save_fig_path='Outputs/LogitLens/DH3B/logits_3b_ptdq_math.jpg',\n",
    "    #kl=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_comparing_lens(\n",
    "    models=(dh3b_fp32, dh3b_bitnet_fp32),\n",
    "    tokenizer=dh3b_tokenizer,\n",
    "    input_ids=MiscPrompts.Q2.value,\n",
    "    start_ix=0, end_ix=15,\n",
    "    save_fig_path='Outputs/LogitLens/DH3B/nwd_3bfp32_ptdq_math.jpg',\n",
    "    #save_fig_path=None,\n",
    "    wasserstein=True,\n",
    "    #top_down=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_topk_lens(\n",
    "    model=dh3b_fp32,\n",
    "    tokenizer=dh3b_tokenizer,\n",
    "    input_ids=MiscPrompts.Q2.value,\n",
    "    start_ix=0, end_ix=15,\n",
    "    topk_n=5,\n",
    "    save_fig_path='Outputs/LogitLens/DH3B/topk5logits_3bfp32_math.jpg'\n",
    "    #save_fig_path=None,\n",
    "    #top_down=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens.plot_topk_lens(\n",
    "    model=dh3b_bitnet_fp32,\n",
    "    tokenizer=dh3b_tokenizer,\n",
    "    input_ids=MiscPrompts.Q2.value,\n",
    "    start_ix=0, end_ix=15,\n",
    "    topk_n=5,\n",
    "    save_fig_path='Outputs/LogitLens/DH3B/topk5logits_ptdq_math.jpg'\n",
    "    #save_fig_path=None,\n",
    "    #entropy=True,\n",
    "    #top_down=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_lens.plot_activation_lens(\n",
    "    model=dh3b_fp32,\n",
    "    tokenizer=dh3b_tokenizer,\n",
    "    input_ids=MiscPrompts.Q2.value,\n",
    "    start_ix=0, end_ix=15,\n",
    "    metric='norm',\n",
    "    save_fig_path='Outputs/LogitLens/DH3B/actnorm_3bfp32_math.jpg'\n",
    "    #save_fig_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_lens.plot_activation_lens(\n",
    "    model=dh3b_bitnet_fp32,\n",
    "    tokenizer=dh3b_tokenizer,\n",
    "    input_ids=MiscPrompts.Q2.value,\n",
    "    start_ix=0, end_ix=15,\n",
    "    metric='norm',\n",
    "    save_fig_path='Outputs/LogitLens/DH3B/actnorm_3b_ptdq_math.jpg'\n",
    "    #save_fig_path=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Learning: SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_tokens(\n",
    "    model=olmo1b_bitnet_fp32,\n",
    "    tokenizer=olmo1b_tokenizer,\n",
    "    inputs=PARAMS.get('prompt'),\n",
    "    multi_tokens=False,\n",
    "    do_log=False,\n",
    "    target_layers=[5],\n",
    "    vis_projection=None,\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    fig_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_tokens(\n",
    "    model=olmo1b_bitnet_fp32,\n",
    "    tokenizer=olmo1b_tokenizer,\n",
    "    inputs=PARAMS.get('prompt'),\n",
    "    multi_tokens=True,\n",
    "    do_log=False,\n",
    "    target_layers=[5],\n",
    "    vis_projection=None,\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    fig_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_tokens(\n",
    "    model=olmo1b_fp32,\n",
    "    tokenizer=olmo1b_tokenizer,\n",
    "    inputs=PARAMS.get('prompt'),\n",
    "    multi_tokens=True,\n",
    "    do_log=False,\n",
    "    target_layers=[5],\n",
    "    vis_projection=None,\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    fig_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_heatmap(\n",
    "    model=dh8b_fp32,\n",
    "    tokenizer=dh8b_tokenizer,\n",
    "    inputs=Texts.T1.value,\n",
    "    do_log=False,\n",
    "    top_k=5,\n",
    "    tokens_per_row=30,\n",
    "    target_layers=[5],\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    fig_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_sae_heatmap(\n",
    "    model=dh8b_bitnet_fp32,\n",
    "    tokenizer=dh8b_tokenizer,\n",
    "    inputs=Texts.T1.value,\n",
    "    do_log=False,\n",
    "    top_k=5,\n",
    "    tokens_per_row=30,\n",
    "    target_layers=[5],\n",
    "    log_path=None,\n",
    "    log_name=None,\n",
    "    fig_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_learning.plot_comparing_heatmap(\n",
    "    models=(dh3b_fp32, dh3b_bitnet_fp32),\n",
    "    tokenizer=dh3b_tokenizer,\n",
    "    inputs=Texts.T1.value,\n",
    "    top_k=5,\n",
    "    tokens_per_row=30,\n",
    "    target_layers=[5],\n",
    "    fig_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Hermes Chatbot Analysis (template only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_dict = {\n",
    "    #'dh.3b-fp32': dh3b_fp32,\n",
    "    #'dh.3b-bitnet.ptdq': dh3b_bitnet_fp32, # Check!\n",
    "    #'dh.3b-bitnet.ptsq': dh3b_bitnet_fp32,\n",
    "    #'dh.8b-fp32': dh8b_fp32,\n",
    "    #'dh.8b-bitnet.ptdq': dh8b_bitnet_fp32,\n",
    "    #'dh.8b-bitnet.ptsq': dh8b_bitnet_fp32,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_analysis.run_chatbot_analysis(\n",
    "    models=dh_dict,\n",
    "    tokenizer=dh8b_tokenizer,\n",
    "    full_path='logs/chatbot_logs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_analysis.plot_chatbot_analysis(\n",
    "    json_logs='logs/chatbot_logs',\n",
    "    parallel_plot=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MechInterp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
